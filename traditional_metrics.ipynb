{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c892d577",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycocoevalcap.bleu.bleu import Bleu\n",
    "from pycocoevalcap.rouge.rouge import Rouge\n",
    "from pycocoevalcap.cider.cider import Cider\n",
    "from pycocoevalcap.meteor.meteor import Meteor\n",
    "from pycocoevalcap.spice.spice import Spice # Requires Java setup for Stanford CoreNLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d818143",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_standard_metrics(references, candidates):\n",
    "    \"\"\"\n",
    "    Calculates standard captioning metrics.\n",
    "\n",
    "    Args:\n",
    "        references (dict): A dictionary mapping image IDs to lists of\n",
    "                           reference strings. e.g., {0: [\"ref1\", \"ref2\"], 1: [\"ref3\"]}\n",
    "        candidates (dict): A dictionary mapping image IDs to a list containing\n",
    "                           a single candidate string. e.g., {0: [\"cand1\"], 1: [\"cand2\"]}\n",
    "                           Note: The library expects a list of *one* candidate per image ID.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing scores for each metric.\n",
    "    \"\"\"\n",
    "\n",
    "    scorers = [\n",
    "        (Bleu(4), [\"Bleu_1\", \"Bleu_2\", \"Bleu_3\", \"Bleu_4\"]), # Calculate BLEU-1 to BLEU-4\n",
    "        # (Meteor(),\"METEOR\"), # Requires JAVA Setup\n",
    "        (Rouge(), \"ROUGE_L\"),\n",
    "        (Cider(), \"CIDEr\"),\n",
    "        # (Spice(), \"SPICE\") # Uncomment if SPICE/Java is set up\n",
    "    ]\n",
    "\n",
    "    all_scores = {}\n",
    "    for scorer, method in scorers:\n",
    "        print(f'Computing {method} score...')\n",
    "        score, scores = scorer.compute_score(references, candidates)\n",
    "        if isinstance(method, list): # Handle BLEU returning multiple scores\n",
    "            for sc, scs, m in zip(score, scores, method):\n",
    "                print(f\"{m}: {sc:.4f}\")\n",
    "                all_scores[m] = sc\n",
    "        else:\n",
    "            print(f\"{method}: {score:.4f}\")\n",
    "            all_scores[method] = score\n",
    "\n",
    "    return all_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cca5439f",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_scores = [\n",
    "  {\n",
    "    \"image_id\": \"000000000139\",\n",
    "    \"image_path\": \"000000000139.jpg\",\n",
    "    \"generated_caption\": \"A woman is standing in a kitchen, looking out the window. The kitchen is furnished with a dining table, chairs, and a refrigerator. There is a TV in the room as well.\",\n",
    "    \"ground_truth_captions\": [\n",
    "      \"A woman stands in the dining area at the table.\",\n",
    "      \"A room with chairs, a table, and a woman in it.\",\n",
    "      \"A woman standing in a kitchen by a window\",\n",
    "      \"A person standing at a table in a room.\",\n",
    "      \"A living area with a television and a table\"\n",
    "    ],\n",
    "    \"similarity_scores\": [\n",
    "      0.864039957523346,\n",
    "      0.8101869225502014,\n",
    "      0.7359619140625,\n",
    "      0.7781818509101868,\n",
    "      0.7816537618637085\n",
    "    ],\n",
    "    \"average_similarity\": 0.7940048813819885,\n",
    "    \"factual_correctness\": 1\n",
    "  },\n",
    "  {\n",
    "    \"image_id\": \"000000000285\",\n",
    "    \"image_path\": \"000000000285.jpg\",\n",
    "    \"generated_caption\": \"A large brown bear is sitting on the grass, looking at the camera.\",\n",
    "    \"ground_truth_captions\": [\n",
    "      \"A big burly grizzly bear is show with grass in the background.\",\n",
    "      \"The large brown bear has a black nose.\",\n",
    "      \"Closeup of a brown bear sitting in a grassy area.\",\n",
    "      \"A large bear that is sitting on grass. \",\n",
    "      \"A close up picture of a brown bear's face.\"\n",
    "    ],\n",
    "    \"similarity_scores\": [\n",
    "      0.8893074989318848,\n",
    "      0.7786434888839722,\n",
    "      0.6692306995391846,\n",
    "      0.86149662733078,\n",
    "      0.8249512910842896\n",
    "    ],\n",
    "    \"average_similarity\": 0.8047259211540222,\n",
    "    \"factual_correctness\": 1\n",
    "  },\n",
    "  {\n",
    "    \"image_id\": \"000000000632\",\n",
    "    \"image_path\": \"000000000632.jpg\",\n",
    "    \"generated_caption\": \"A bedroom with a blue bedspread and a window with a view of trees. The room also features a dresser, a mirror, and a bookshelf filled with books.\",\n",
    "    \"ground_truth_captions\": [\n",
    "      \"Bedroom scene with a bookcase, blue comforter and window.\",\n",
    "      \"A bedroom with a bookshelf full of books.\",\n",
    "      \"This room has a bed with blue sheets and a large bookcase\",\n",
    "      \"A bed and a mirror in a small room.\",\n",
    "      \"a bed room with a neatly made bed a window and a book shelf\"\n",
    "    ],\n",
    "    \"similarity_scores\": [\n",
    "      0.8228579759597778,\n",
    "      0.8787494897842407,\n",
    "      0.8664553761482239,\n",
    "      0.8357845544815063,\n",
    "      0.8780856728553772\n",
    "    ],\n",
    "    \"average_similarity\": 0.8563866138458252,\n",
    "    \"factual_correctness\": 1\n",
    "  },\n",
    "  {\n",
    "    \"image_id\": \"000000000724\",\n",
    "    \"image_path\": \"000000000724.jpg\",\n",
    "    \"generated_caption\": \"A stop sign is upside down on a pole, located on a street corner.\",\n",
    "    \"ground_truth_captions\": [\n",
    "      \"A stop sign is mounted upside-down on it's post. \",\n",
    "      \"A stop sign that is hanging upside down.\",\n",
    "      \"An upside down stop sign by the road.\",\n",
    "      \"a stop sign put upside down on a metal pole \",\n",
    "      \"A stop sign installed upside down on a street corner\"\n",
    "    ],\n",
    "    \"similarity_scores\": [\n",
    "      0.935600757598877,\n",
    "      0.8545207977294922,\n",
    "      0.8760558366775513,\n",
    "      0.8726543188095093,\n",
    "      0.8638495206832886\n",
    "    ],\n",
    "    \"average_similarity\": 0.8805362462997437,\n",
    "    \"factual_correctness\": 1\n",
    "  },\n",
    "  {\n",
    "    \"image_id\": \"000000000776\",\n",
    "    \"image_path\": \"000000000776.jpg\",\n",
    "    \"generated_caption\": \"A group of teddy bears are sitting on a bed, with one teddy bear on top of another.\",\n",
    "    \"ground_truth_captions\": [\n",
    "      \"Three teddy bears, each a different color, snuggling together.\",\n",
    "      \"Three stuffed animals are sitting on a bed. \",\n",
    "      \"three teddy bears giving each other a hug\",\n",
    "      \"A group of three stuffed animal teddy bears.\",\n",
    "      \"Three stuffed bears hugging and sitting on a blue pillow\"\n",
    "    ],\n",
    "    \"similarity_scores\": [\n",
    "      0.8922926187515259,\n",
    "      0.9345947504043579,\n",
    "      0.8287369012832642,\n",
    "      0.8500735759735107,\n",
    "      0.7993433475494385\n",
    "    ],\n",
    "    \"average_similarity\": 0.8610082387924194,\n",
    "    \"factual_correctness\": 1\n",
    "  },\n",
    "  {\n",
    "    \"image_id\": \"000000000785\",\n",
    "    \"image_path\": \"000000000785.jpg\",\n",
    "    \"generated_caption\": \"A woman wearing a red jacket and black pants is skiing down a snowy slope.\",\n",
    "    \"ground_truth_captions\": [\n",
    "      \"A woman posing for the camera standing on skis.\",\n",
    "      \"a woman standing on skiis while posing for the camera\",\n",
    "      \"A woman in a red jacket skiing down a slope\",\n",
    "      \"A young woman is skiing down the mountain slope. \",\n",
    "      \"a person on skis makes her way through the snow\"\n",
    "    ],\n",
    "    \"similarity_scores\": [\n",
    "      0.8044158816337585,\n",
    "      0.7669301629066467,\n",
    "      0.7962386012077332,\n",
    "      0.9632653594017029,\n",
    "      0.7827343344688416\n",
    "    ],\n",
    "    \"average_similarity\": 0.8227168679237366,\n",
    "    \"factual_correctness\": 1\n",
    "  },\n",
    "  {\n",
    "    \"image_id\": \"000000000802\",\n",
    "    \"image_path\": \"000000000802.jpg\",\n",
    "    \"generated_caption\": \"A kitchen with a white refrigerator, a white stove, and a wooden cabinet.\",\n",
    "    \"ground_truth_captions\": [\n",
    "      \"A kitchen with a refrigerator, stove and oven with cabinets.\",\n",
    "      \"A white oven and a white refrigerator are in the kitchen.\",\n",
    "      \"The refrigerator is brand new and was delivered today.\",\n",
    "      \"Stark white appliances stand out against brown wooden cabinets.\",\n",
    "      \"Kitchen appliances and cabinets as seen through opening.\"\n",
    "    ],\n",
    "    \"similarity_scores\": [\n",
    "      0.9302010536193848,\n",
    "      0.8662447929382324,\n",
    "      0.7640253305435181,\n",
    "      0.8614518642425537,\n",
    "      0.7791967988014221\n",
    "    ],\n",
    "    \"average_similarity\": 0.8402239680290222,\n",
    "    \"factual_correctness\": 1\n",
    "  },\n",
    "  {\n",
    "    \"image_id\": \"000000000872\",\n",
    "    \"image_path\": \"000000000872.jpg\",\n",
    "    \"generated_caption\": \"Two baseball players are running on a field, one of them holding a baseball glove.\",\n",
    "    \"ground_truth_captions\": [\n",
    "      \"A couple of baseball player standing on a field.\",\n",
    "      \"Two men playing baseball in a field on a sunny day.\",\n",
    "      \"two baseball players are playing baseball on a field\",\n",
    "      \"A couple of men play baseball and the batter runs for base.\",\n",
    "      \"Two guys playing baseball, with trees in the back.\"\n",
    "    ],\n",
    "    \"similarity_scores\": [\n",
    "      0.7457690238952637,\n",
    "      0.7638369202613831,\n",
    "      0.9126253128051758,\n",
    "      0.9091525673866272,\n",
    "      0.8205470442771912\n",
    "    ],\n",
    "    \"average_similarity\": 0.8303861737251281,\n",
    "    \"factual_correctness\": 1\n",
    "  },\n",
    "  {\n",
    "    \"image_id\": \"000000000885\",\n",
    "    \"image_path\": \"000000000885.jpg\",\n",
    "    \"generated_caption\": \"A man in a white shirt and white shorts is playing tennis on a court. He is holding a tennis racket and appears to be in the middle of a swing. The man is wearing a hat and is focused on the game.\",\n",
    "    \"ground_truth_captions\": [\n",
    "      \"a male tennis player in white shorts is playing tennis\",\n",
    "      \"This woman has just returned a volley in tennis\",\n",
    "      \"A man holding a tennis racket playing tennis.\",\n",
    "      \"The man balances on one leg after serving a tennis ball.\",\n",
    "      \"Someone playing in a tennis tournament with a crowd looking on.\"\n",
    "    ],\n",
    "    \"similarity_scores\": [\n",
    "      0.7916176319122314,\n",
    "      0.6029044389724731,\n",
    "      0.7826493382453918,\n",
    "      0.7831728458404541,\n",
    "      0.730663001537323\n",
    "    ],\n",
    "    \"average_similarity\": 0.7382014513015747,\n",
    "    \"factual_correctness\": 1\n",
    "  },\n",
    "  {\n",
    "    \"image_id\": \"000000001000\",\n",
    "    \"image_path\": \"000000001000.jpg\",\n",
    "    \"generated_caption\": \"A group of young tennis players posing for a photo on a tennis court.\",\n",
    "    \"ground_truth_captions\": [\n",
    "      \"The people are posing for a group photo.\",\n",
    "      \"a large family poses for picture on tennis court\",\n",
    "      \"A group of young children standing next to each other.\",\n",
    "      \"A group of people that are standing near a tennis net.\",\n",
    "      \"A group of kids posing for a picture on a tennis court.\"\n",
    "    ],\n",
    "    \"similarity_scores\": [\n",
    "      0.8121464848518372,\n",
    "      0.8014275431632996,\n",
    "      0.9332407712936401,\n",
    "      0.9266008734703064,\n",
    "      0.96210777759552\n",
    "    ],\n",
    "    \"average_similarity\": 0.8871046900749207,\n",
    "    \"factual_correctness\": 1\n",
    "  },\n",
    "  {\n",
    "    \"image_id\": \"000000001268\",\n",
    "    \"image_path\": \"000000001268.jpg\",\n",
    "    \"generated_caption\": \"A man is sitting on a bench near a body of water, with a bird standing nearby. Another person is taking a picture of the scene.\",\n",
    "    \"ground_truth_captions\": [\n",
    "      \"A beautiful woman taking a picture with her smart phone.\",\n",
    "      \"People underneath an arched bridge near the water.\",\n",
    "      \"A girl is taking a picture of people fishing.\",\n",
    "      \"The woman is taking a photo of the white goose next to the river.\",\n",
    "      \"A waterway under a bridge with people sitting down and a woman taking a photo.\"\n",
    "    ],\n",
    "    \"similarity_scores\": [\n",
    "      0.782329797744751,\n",
    "      0.8064131140708923,\n",
    "      0.9176195859909058,\n",
    "      0.9087253212928772,\n",
    "      0.792995035648346\n",
    "    ],\n",
    "    \"average_similarity\": 0.8416165709495544,\n",
    "    \"factual_correctness\": 1\n",
    "  },\n",
    "  {\n",
    "    \"image_id\": \"000000001296\",\n",
    "    \"image_path\": \"000000001296.jpg\",\n",
    "    \"generated_caption\": \"A woman is holding a Hello Kitty cell phone and looking at it.\",\n",
    "    \"ground_truth_captions\": [\n",
    "      \"A woman holding a Hello Kitty phone on her hands.\",\n",
    "      \"A woman holds up her phone in front of her face.\",\n",
    "      \"A woman in white shirt holding up a cellphone.\",\n",
    "      \"A woman checking her cell phone with a hello kitty case.\",\n",
    "      \"The Asian girl is holding her Miss Kitty phone\"\n",
    "    ],\n",
    "    \"similarity_scores\": [\n",
    "      0.895054042339325,\n",
    "      0.963775098323822,\n",
    "      0.8877794146537781,\n",
    "      0.8548141717910767,\n",
    "      0.9150592684745789\n",
    "    ],\n",
    "    \"average_similarity\": 0.9032963991165162,\n",
    "    \"factual_correctness\": 1\n",
    "  },\n",
    "  {\n",
    "    \"image_id\": \"000000001353\",\n",
    "    \"image_path\": \"000000001353.jpg\",\n",
    "    \"generated_caption\": \"A group of children are riding on a merry-go-round, enjoying the ride together.\",\n",
    "    \"ground_truth_captions\": [\n",
    "      \"some children are riding on a mini orange train\",\n",
    "      \"Several children are riding on a toy train ride.\",\n",
    "      \"The children are riding on an indoor train. \",\n",
    "      \"Several children on a small  indoor kiddie train.\",\n",
    "      \"A group of children ride on an indoor train.\"\n",
    "    ],\n",
    "    \"similarity_scores\": [\n",
    "      0.8839945793151855,\n",
    "      0.935627818107605,\n",
    "      0.9296435117721558,\n",
    "      0.8595176935195923,\n",
    "      0.9184918403625488\n",
    "    ],\n",
    "    \"average_similarity\": 0.9054550886154175,\n",
    "    \"factual_correctness\": 1\n",
    "  },\n",
    "  {\n",
    "    \"image_id\": \"000000001425\",\n",
    "    \"image_path\": \"000000001425.jpg\",\n",
    "    \"generated_caption\": \"A half-eaten pastry, possibly a doughnut, is sitting on a plate next to a bowl of sauce.\",\n",
    "    \"ground_truth_captions\": [\n",
    "      \"A meal is lying on a plate on a table.\",\n",
    "      \"part of a sandwich sitting on a table\",\n",
    "      \"A plate with a burger that is halfway eaten. \",\n",
    "      \"A half eaten meal sitting on a plate.\",\n",
    "      \"A sandwich with a bite taken on a plate.\"\n",
    "    ],\n",
    "    \"similarity_scores\": [\n",
    "      0.9454461932182312,\n",
    "      0.7800353765487671,\n",
    "      0.8442324995994568,\n",
    "      0.8539847731590271,\n",
    "      0.8317437171936035\n",
    "    ],\n",
    "    \"average_similarity\": 0.8510885119438172,\n",
    "    \"factual_correctness\": 1\n",
    "  },\n",
    "  {\n",
    "    \"image_id\": \"000000001490\",\n",
    "    \"image_path\": \"000000001490.jpg\",\n",
    "    \"generated_caption\": \"A person is paddling on a surfboard in the ocean, surrounded by a calm sea.\",\n",
    "    \"ground_truth_captions\": [\n",
    "      \"A man in a wet suit stands on a surfboard and rows with a paddle.\",\n",
    "      \"A paddle boarder on a large, still body of water.\",\n",
    "      \"A man is holding a long racquet on a surfboard in the middle of the sea.\",\n",
    "      \"Black and white of a person wearing a wetsuit standing on a surfboard and holding out a paddle, in a large body of water outside.\",\n",
    "      \"A man with a wet suit on standing on a surfboard in the water.\"\n",
    "    ],\n",
    "    \"similarity_scores\": [\n",
    "      0.8862621784210205,\n",
    "      0.8295203447341919,\n",
    "      0.9120904803276062,\n",
    "      0.8085383176803589,\n",
    "      0.8620437979698181\n",
    "    ],\n",
    "    \"average_similarity\": 0.8596910238265991,\n",
    "    \"factual_correctness\": 1\n",
    "  },\n",
    "  {\n",
    "    \"image_id\": \"000000001503\",\n",
    "    \"image_path\": \"000000001503.jpg\",\n",
    "    \"generated_caption\": \"A white computer monitor is sitting on a desk next to a laptop.\",\n",
    "    \"ground_truth_captions\": [\n",
    "      \"A computer on a desk next to a laptop.\",\n",
    "      \"A picture of an iMac desktop next to a Mac laptop on a desk. \",\n",
    "      \"Two apple computers are on a white desk\",\n",
    "      \"A laptop and desktop computer on a white desk\",\n",
    "      \"A computer desk with several pieces of computer equipment.\"\n",
    "    ],\n",
    "    \"similarity_scores\": [\n",
    "      0.8663958311080933,\n",
    "      0.8651009798049927,\n",
    "      0.9453930258750916,\n",
    "      0.899527370929718,\n",
    "      0.8212477564811707\n",
    "    ],\n",
    "    \"average_similarity\": 0.8795329928398132,\n",
    "    \"factual_correctness\": 1\n",
    "  },\n",
    "  {\n",
    "    \"image_id\": \"000000001532\",\n",
    "    \"image_path\": \"000000001532.jpg\",\n",
    "    \"generated_caption\": \"A busy highway with multiple cars and trucks driving under a freeway sign.\",\n",
    "    \"ground_truth_captions\": [\n",
    "      \"A street scene with focus on the street signs on an overpass.\",\n",
    "      \"Many cars traveling on a busy road with exit signs overhead.\",\n",
    "      \"California traffic goes by road signs on an overpass indicating famous Hollywood streets.\",\n",
    "      \"Some cars on the freeway are exiting onto Sunset Blvd.\",\n",
    "      \"Cars and trucks driving under the underpass with street signs directing them where to go\"\n",
    "    ],\n",
    "    \"similarity_scores\": [\n",
    "      0.8697336912155151,\n",
    "      0.937811017036438,\n",
    "      0.8356293439865112,\n",
    "      0.7796680927276611,\n",
    "      0.908282458782196\n",
    "    ],\n",
    "    \"average_similarity\": 0.8662249207496643,\n",
    "    \"factual_correctness\": 1\n",
    "  },\n",
    "  {\n",
    "    \"image_id\": \"000000001584\",\n",
    "    \"image_path\": \"000000001584.jpg\",\n",
    "    \"generated_caption\": \"A red double-decker bus is driving down a street, with a building in the background.\",\n",
    "    \"ground_truth_captions\": [\n",
    "      \"The red, double decker bus is driving past other buses. \",\n",
    "      \"A red double decker bus driving down a city street.\",\n",
    "      \"A red bus is driving on the road.\",\n",
    "      \"A double decker bus rolls along the streets.\",\n",
    "      \"a red double decker bus that is in the middle of the road\"\n",
    "    ],\n",
    "    \"similarity_scores\": [\n",
    "      0.8889199495315552,\n",
    "      0.843612015247345,\n",
    "      0.8969419002532959,\n",
    "      0.8537344336509705,\n",
    "      0.8123933672904968\n",
    "    ],\n",
    "    \"average_similarity\": 0.8591203331947327,\n",
    "    \"factual_correctness\": 1\n",
    "  },\n",
    "  {\n",
    "    \"image_id\": \"000000001675\",\n",
    "    \"image_path\": \"000000001675.jpg\",\n",
    "    \"generated_caption\": \"A black and white cat is laying on a laptop computer.\",\n",
    "    \"ground_truth_captions\": [\n",
    "      \"A cat resting on an open laptop computer.\",\n",
    "      \"A black fluffy cat sitting on top of a computer keyboard.\",\n",
    "      \"A black cat is sitting on a metal platform. \",\n",
    "      \"The large cat is resting comfortably behind the laptop screen. \",\n",
    "      \"A black and white cat relaxing inside a laptop.\"\n",
    "    ],\n",
    "    \"similarity_scores\": [\n",
    "      0.8737772703170776,\n",
    "      0.8860299587249756,\n",
    "      0.9559348225593567,\n",
    "      0.8950818777084351,\n",
    "      0.8904887437820435\n",
    "    ],\n",
    "    \"average_similarity\": 0.9002625346183777,\n",
    "    \"factual_correctness\": 1\n",
    "  },\n",
    "  {\n",
    "    \"image_id\": \"000000001761\",\n",
    "    \"image_path\": \"000000001761.jpg\",\n",
    "    \"generated_caption\": \"A large airplane is flying over a bridge in the city, with the bridge's arches visible below. The airplane is positioned in the middle of the scene, and the bridge spans the entire width of the image.\",\n",
    "    \"ground_truth_captions\": [\n",
    "      \"Two planes flying in the sky over a bridge.\",\n",
    "      \"A sky photo to jumbo jet airplanes over a bridge.\",\n",
    "      \"Two planes fly over a bridge in Sydney, Australia, with the Sydney Opera House in the background.\",\n",
    "      \"two jets are flying over a bridge and some water\",\n",
    "      \"Two airplanes flying in the sky above a black bridge.\"\n",
    "    ],\n",
    "    \"similarity_scores\": [\n",
    "      0.7212255001068115,\n",
    "      0.7172260880470276,\n",
    "      0.8507752418518066,\n",
    "      0.7716518044471741,\n",
    "      0.7321873903274536\n",
    "    ],\n",
    "    \"average_similarity\": 0.7586132049560547,\n",
    "    \"factual_correctness\": 1\n",
    "  },\n",
    "  {\n",
    "    \"image_id\": \"000000001818\",\n",
    "    \"image_path\": \"000000001818.jpg\",\n",
    "    \"generated_caption\": \"A zebra is nuzzling its head under the belly of another zebra, possibly a mother and her baby.\",\n",
    "    \"ground_truth_captions\": [\n",
    "      \"A zebra in the grass who is cleaning himself. \",\n",
    "      \"A baby giraffe drinking milk from it's mother in a field.\",\n",
    "      \"A baby zebra is suckling milk from its mother.\",\n",
    "      \"a baby zebra nursing from an adult zebra\",\n",
    "      \"Baby zebra sucking milk from its mothers teat. \"\n",
    "    ],\n",
    "    \"similarity_scores\": [\n",
    "      0.835252046585083,\n",
    "      0.7838693857192993,\n",
    "      0.9422412514686584,\n",
    "      0.8128725290298462,\n",
    "      0.8098879456520081\n",
    "    ],\n",
    "    \"average_similarity\": 0.836824631690979,\n",
    "    \"factual_correctness\": 1\n",
    "  },\n",
    "  {\n",
    "    \"image_id\": \"000000001993\",\n",
    "    \"image_path\": \"000000001993.jpg\",\n",
    "    \"generated_caption\": \"A bedroom with a bed, a chair, and a dining table. The bed has a colorful comforter on it.\",\n",
    "    \"ground_truth_captions\": [\n",
    "      \"A bedroom with a bed and small table near by.\",\n",
    "      \"View of an apartment room with a bed an table and a view out the window.\",\n",
    "      \"A simple modern bedroom sheets on the bed\",\n",
    "      \"A bed room that has a table, chairs, and bed in it.\",\n",
    "      \"A room with purple walls, carpet and bed comforter.\"\n",
    "    ],\n",
    "    \"similarity_scores\": [\n",
    "      0.9260177612304688,\n",
    "      0.8000837564468384,\n",
    "      0.8219413757324219,\n",
    "      0.9223857522010803,\n",
    "      0.9159104824066162\n",
    "    ],\n",
    "    \"average_similarity\": 0.8772678256034852,\n",
    "    \"factual_correctness\": 1\n",
    "  },\n",
    "  {\n",
    "    \"image_id\": \"000000002006\",\n",
    "    \"image_path\": \"000000002006.jpg\",\n",
    "    \"generated_caption\": \"A purple bus is driving down the street, with a man sitting in the driver's seat. The bus is heading towards the metro center, and there is a handicap sign on the front.\",\n",
    "    \"ground_truth_captions\": [\n",
    "      \"a big purple bus parked in a parking spot\",\n",
    "      \"A purple bus can't be missed on the city streets.\",\n",
    "      \"a big purple public bus called south tyne\",\n",
    "      \"A city bus drives through a city area.\",\n",
    "      \"City bus driving through pedestrian saturated area near crosswalk.\"\n",
    "    ],\n",
    "    \"similarity_scores\": [\n",
    "      0.8375006914138794,\n",
    "      0.8596506714820862,\n",
    "      0.7881979942321777,\n",
    "      0.8768660426139832,\n",
    "      0.7189272046089172\n",
    "    ],\n",
    "    \"average_similarity\": 0.8162285208702087,\n",
    "    \"factual_correctness\": 1\n",
    "  },\n",
    "  {\n",
    "    \"image_id\": \"000000002149\",\n",
    "    \"image_path\": \"000000002149.jpg\",\n",
    "    \"generated_caption\": \"A bowl filled with green apples, some of which are placed on top of each other.\",\n",
    "    \"ground_truth_captions\": [\n",
    "      \"A large white bowl of many green apples. \",\n",
    "      \"A white bowl of green granny smith apples.\",\n",
    "      \"A white bowl filled with green Granny Smith apples.\",\n",
    "      \"A bowl filled with many shiny  green apples.\",\n",
    "      \"A bowl full of fresh green apples are kept.\"\n",
    "    ],\n",
    "    \"similarity_scores\": [\n",
    "      0.9226332902908325,\n",
    "      0.8898783922195435,\n",
    "      0.9003108739852905,\n",
    "      0.9271273016929626,\n",
    "      0.8254778981208801\n",
    "    ],\n",
    "    \"average_similarity\": 0.8930855512619018,\n",
    "    \"factual_correctness\": 1\n",
    "  },\n",
    "  {\n",
    "    \"image_id\": \"000000002153\",\n",
    "    \"image_path\": \"000000002153.jpg\",\n",
    "    \"generated_caption\": \"A baseball player is holding a bat, ready to swing, while the catcher and umpire are positioned behind him.\",\n",
    "    \"ground_truth_captions\": [\n",
    "      \"Batter preparing to swing at pitch during major game.\",\n",
    "      \"A baseball player swinging a bat over home plate.\",\n",
    "      \"A baseball player with a bat in his hand as the pitcher gets ready to throw the ball. \",\n",
    "      \"A baseball game where the batter is waiting for the pitch.\",\n",
    "      \"there is a male tennis player that is at base\"\n",
    "    ],\n",
    "    \"similarity_scores\": [\n",
    "      0.5830568671226501,\n",
    "      0.8184176683425903,\n",
    "      0.7827561497688293,\n",
    "      0.7379368543624878,\n",
    "      0.7012471556663513\n",
    "    ],\n",
    "    \"average_similarity\": 0.7246829390525817,\n",
    "    \"factual_correctness\": 1\n",
    "  }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df26b9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_traditional_scores(data):\n",
    "    \"\"\"\n",
    "    Adds traditional captioning scores to each item in the input data list.\n",
    "\n",
    "    Args:\n",
    "        data (list): A list of dictionaries, each containing image info,\n",
    "                     generated caption, and ground truth captions.\n",
    "\n",
    "    Returns:\n",
    "        list: The input list with an added 'traditional_scores' key\n",
    "              in each dictionary.\n",
    "    \"\"\"\n",
    "    processed_data = []\n",
    "    for item in data:\n",
    "        image_id = item['image_id']\n",
    "        references = {image_id: item['ground_truth_captions']}\n",
    "        candidates = {image_id: [item['generated_caption']]}\n",
    "\n",
    "        # Calculate scores for the current item\n",
    "        scores = evaluate_standard_metrics(references, candidates)\n",
    "\n",
    "        # Add the scores to the item\n",
    "        item['traditional_scores'] = scores\n",
    "        processed_data.append(item)\n",
    "\n",
    "    return processed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "68cb6c3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating BLEU and ROUGE scores...\n",
      "{'testlen': 32, 'reflen': 11, 'guess': [32, 31, 30, 29], 'correct': [15, 6, 1, 0]}\n",
      "ratio: 2.909090908826446\n",
      "{'testlen': 13, 'reflen': 12, 'guess': [13, 12, 11, 10], 'correct': [8, 6, 2, 0]}\n",
      "ratio: 1.0833333332430557\n",
      "{'testlen': 28, 'reflen': 14, 'guess': [28, 27, 26, 25], 'correct': [14, 6, 2, 1]}\n",
      "ratio: 1.999999999857143\n",
      "{'testlen': 14, 'reflen': 10, 'guess': [14, 13, 12, 11], 'correct': [10, 7, 5, 2]}\n",
      "ratio: 1.3999999998600001\n",
      "{'testlen': 18, 'reflen': 10, 'guess': [18, 17, 16, 15], 'correct': [9, 6, 3, 1]}\n",
      "ratio: 1.79999999982\n",
      "{'testlen': 15, 'reflen': 10, 'guess': [15, 14, 13, 12], 'correct': [10, 6, 3, 0]}\n",
      "ratio: 1.4999999998500002\n",
      "{'testlen': 13, 'reflen': 11, 'guess': [13, 12, 11, 10], 'correct': [9, 5, 2, 1]}\n",
      "ratio: 1.181818181710744\n",
      "{'testlen': 15, 'reflen': 12, 'guess': [15, 14, 13, 12], 'correct': [9, 3, 1, 0]}\n",
      "ratio: 1.2499999998958335\n",
      "{'testlen': 43, 'reflen': 11, 'guess': [43, 42, 41, 40], 'correct': [15, 10, 5, 3]}\n",
      "ratio: 3.909090908735537\n",
      "{'testlen': 14, 'reflen': 12, 'guess': [14, 13, 12, 11], 'correct': [11, 8, 5, 2]}\n",
      "ratio: 1.1666666665694445\n",
      "{'testlen': 26, 'reflen': 15, 'guess': [26, 25, 24, 23], 'correct': [12, 5, 3, 2]}\n",
      "ratio: 1.7333333332177778\n",
      "{'testlen': 13, 'reflen': 11, 'guess': [13, 12, 11, 10], 'correct': [9, 6, 2, 1]}\n",
      "ratio: 1.181818181710744\n",
      "{'testlen': 13, 'reflen': 9, 'guess': [13, 12, 11, 10], 'correct': [9, 7, 5, 3]}\n",
      "ratio: 1.4444444442839508\n",
      "{'testlen': 17, 'reflen': 10, 'guess': [17, 16, 15, 14], 'correct': [8, 3, 2, 0]}\n",
      "ratio: 1.69999999983\n",
      "{'testlen': 15, 'reflen': 15, 'guess': [15, 14, 13, 12], 'correct': [10, 4, 3, 2]}\n",
      "ratio: 0.9999999999333334\n",
      "{'testlen': 13, 'reflen': 14, 'guess': [13, 12, 11, 10], 'correct': [10, 6, 5, 4]}\n",
      "ratio: 0.9285714285051022\n",
      "{'testlen': 13, 'reflen': 13, 'guess': [13, 12, 11, 10], 'correct': [10, 3, 2, 1]}\n",
      "ratio: 0.9999999999230771\n",
      "{'testlen': 15, 'reflen': 13, 'guess': [15, 14, 13, 12], 'correct': [9, 6, 2, 0]}\n",
      "ratio: 1.1538461537573965\n",
      "{'testlen': 11, 'reflen': 11, 'guess': [11, 10, 9, 8], 'correct': [10, 7, 3, 2]}\n",
      "ratio: 0.999999999909091\n",
      "{'testlen': 37, 'reflen': 17, 'guess': [37, 36, 35, 34], 'correct': [11, 6, 3, 2]}\n",
      "ratio: 2.1764705881072666\n",
      "{'testlen': 18, 'reflen': 11, 'guess': [18, 17, 16, 15], 'correct': [7, 2, 0, 0]}\n",
      "ratio: 1.6363636362148761\n",
      "{'testlen': 19, 'reflen': 16, 'guess': [19, 18, 17, 16], 'correct': [10, 5, 2, 1]}\n",
      "ratio: 1.1874999999257811\n",
      "{'testlen': 33, 'reflen': 10, 'guess': [33, 32, 31, 30], 'correct': [9, 3, 1, 0]}\n",
      "ratio: 3.29999999967\n",
      "{'testlen': 16, 'reflen': 9, 'guess': [16, 15, 14, 13], 'correct': [7, 4, 3, 2]}\n",
      "ratio: 1.7777777775802468\n",
      "{'testlen': 19, 'reflen': 18, 'guess': [19, 18, 17, 16], 'correct': [8, 3, 1, 0]}\n",
      "ratio: 1.0555555554969136\n",
      "\n",
      "Calculating CIDEr score...\n",
      "CIDEr (Avg): 0.6712\n"
     ]
    }
   ],
   "source": [
    "processed_scores = add_traditional_scores(original_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "56b9b2e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'image_id': '000000000139', 'image_path': '000000000139.jpg', 'generated_caption': 'A woman is standing in a kitchen, looking out the window. The kitchen is furnished with a dining table, chairs, and a refrigerator. There is a TV in the room as well.', 'ground_truth_captions': ['A woman stands in the dining area at the table.', 'A room with chairs, a table, and a woman in it.', 'A woman standing in a kitchen by a window', 'A person standing at a table in a room.', 'A living area with a television and a table'], 'similarity_scores': [0.864039957523346, 0.8101869225502014, 0.7359619140625, 0.7781818509101868, 0.7816537618637085], 'average_similarity': 0.7940048813819885, 'factual_correctness': 1, 'traditional_scores': {'Bleu_1': 0.46874999998535166, 'Bleu_2': 0.3012072483288726, 'Bleu_3': 0.14461162095957636, 'Bleu_4': 1.7970199400853487e-05, 'ROUGE_L': np.float64(0.3798932384341636), 'CIDEr': np.float64(0.0006951093543207995)}}, {'image_id': '000000000285', 'image_path': '000000000285.jpg', 'generated_caption': 'A large brown bear is sitting on the grass, looking at the camera.', 'ground_truth_captions': ['A big burly grizzly bear is show with grass in the background.', 'The large brown bear has a black nose.', 'Closeup of a brown bear sitting in a grassy area.', 'A large bear that is sitting on grass. ', \"A close up picture of a brown bear's face.\"], 'similarity_scores': [0.8893074989318848, 0.7786434888839722, 0.6692306995391846, 0.86149662733078, 0.8249512910842896], 'average_similarity': 0.8047259211540222, 'factual_correctness': 1, 'traditional_scores': {'Bleu_1': 0.6153846153372783, 'Bleu_2': 0.5547001961807821, 'Bleu_3': 0.38245879273003236, 'Bleu_4': 4.863383167652981e-05, 'ROUGE_L': np.float64(0.563944530046225), 'CIDEr': np.float64(0.9213898910098082)}}, {'image_id': '000000000632', 'image_path': '000000000632.jpg', 'generated_caption': 'A bedroom with a blue bedspread and a window with a view of trees. The room also features a dresser, a mirror, and a bookshelf filled with books.', 'ground_truth_captions': ['Bedroom scene with a bookcase, blue comforter and window.', 'A bedroom with a bookshelf full of books.', 'This room has a bed with blue sheets and a large bookcase', 'A bed and a mirror in a small room.', 'a bed room with a neatly made bed a window and a book shelf'], 'similarity_scores': [0.8228579759597778, 0.8787494897842407, 0.8664553761482239, 0.8357845544815063, 0.8780856728553772], 'average_similarity': 0.8563866138458252, 'factual_correctness': 1, 'traditional_scores': {'Bleu_1': 0.4999999999821429, 'Bleu_2': 0.3333333333212081, 'Bleu_3': 0.20445828459126097, 'Bleu_4': 0.13597796343320864, 'ROUGE_L': np.float64(0.37044534412955465), 'CIDEr': np.float64(0.010187029736029356)}}, {'image_id': '000000000724', 'image_path': '000000000724.jpg', 'generated_caption': 'A stop sign is upside down on a pole, located on a street corner.', 'ground_truth_captions': [\"A stop sign is mounted upside-down on it's post. \", 'A stop sign that is hanging upside down.', 'An upside down stop sign by the road.', 'a stop sign put upside down on a metal pole ', 'A stop sign installed upside down on a street corner'], 'similarity_scores': [0.935600757598877, 0.8545207977294922, 0.8760558366775513, 0.8726543188095093, 0.8638495206832886], 'average_similarity': 0.8805362462997437, 'factual_correctness': 1, 'traditional_scores': {'Bleu_1': 0.714285714234694, 'Bleu_2': 0.6201736729000406, 'Bleu_3': 0.5431733703813888, 'Bleu_4': 0.41315515907730943, 'ROUGE_L': np.float64(0.6873239436619719), 'CIDEr': np.float64(1.9751996837284862)}}, {'image_id': '000000000776', 'image_path': '000000000776.jpg', 'generated_caption': 'A group of teddy bears are sitting on a bed, with one teddy bear on top of another.', 'ground_truth_captions': ['Three teddy bears, each a different color, snuggling together.', 'Three stuffed animals are sitting on a bed. ', 'three teddy bears giving each other a hug', 'A group of three stuffed animal teddy bears.', 'Three stuffed bears hugging and sitting on a blue pillow'], 'similarity_scores': [0.8922926187515259, 0.9345947504043579, 0.8287369012832642, 0.8500735759735107, 0.7993433475494385], 'average_similarity': 0.8610082387924194, 'factual_correctness': 1, 'traditional_scores': {'Bleu_1': 0.49999999997222233, 'Bleu_2': 0.4200840251843786, 'Bleu_3': 0.32103905506656993, 'Bleu_4': 0.21671830062472106, 'ROUGE_L': np.float64(0.3306233062330623), 'CIDEr': np.float64(0.2114007596200929)}}, {'image_id': '000000000785', 'image_path': '000000000785.jpg', 'generated_caption': 'A woman wearing a red jacket and black pants is skiing down a snowy slope.', 'ground_truth_captions': ['A woman posing for the camera standing on skis.', 'a woman standing on skiis while posing for the camera', 'A woman in a red jacket skiing down a slope', 'A young woman is skiing down the mountain slope. ', 'a person on skis makes her way through the snow'], 'similarity_scores': [0.8044158816337585, 0.7669301629066467, 0.7962386012077332, 0.9632653594017029, 0.7827343344688416], 'average_similarity': 0.8227168679237366, 'factual_correctness': 1, 'traditional_scores': {'Bleu_1': 0.6666666666222223, 'Bleu_2': 0.5345224837879413, 'Bleu_3': 0.40398938376812005, 'Bleu_4': 4.841524712673482e-05, 'ROUGE_L': np.float64(0.6639455782312924), 'CIDEr': np.float64(0.6914948680419658)}}, {'image_id': '000000000802', 'image_path': '000000000802.jpg', 'generated_caption': 'A kitchen with a white refrigerator, a white stove, and a wooden cabinet.', 'ground_truth_captions': ['A kitchen with a refrigerator, stove and oven with cabinets.', 'A white oven and a white refrigerator are in the kitchen.', 'The refrigerator is brand new and was delivered today.', 'Stark white appliances stand out against brown wooden cabinets.', 'Kitchen appliances and cabinets as seen through opening.'], 'similarity_scores': [0.9302010536193848, 0.8662447929382324, 0.7640253305435181, 0.8614518642425537, 0.7791967988014221], 'average_similarity': 0.8402239680290222, 'factual_correctness': 1, 'traditional_scores': {'Bleu_1': 0.692307692254438, 'Bleu_2': 0.537086155486539, 'Bleu_3': 0.37431888793482826, 'Bleu_4': 0.2691109110108217, 'ROUGE_L': np.float64(0.5343065693430658), 'CIDEr': np.float64(0.583240573035761)}}, {'image_id': '000000000872', 'image_path': '000000000872.jpg', 'generated_caption': 'Two baseball players are running on a field, one of them holding a baseball glove.', 'ground_truth_captions': ['A couple of baseball player standing on a field.', 'Two men playing baseball in a field on a sunny day.', 'two baseball players are playing baseball on a field', 'A couple of men play baseball and the batter runs for base.', 'Two guys playing baseball, with trees in the back.'], 'similarity_scores': [0.7457690238952637, 0.7638369202613831, 0.9126253128051758, 0.9091525673866272, 0.8205470442771912], 'average_similarity': 0.8303861737251281, 'factual_correctness': 1, 'traditional_scores': {'Bleu_1': 0.5999999999600001, 'Bleu_2': 0.35856858277555986, 'Bleu_3': 0.2146513902599977, 'Bleu_4': 3.0130404890538334e-05, 'ROUGE_L': np.float64(0.4363376251788269), 'CIDEr': np.float64(0.4013030481470843)}}, {'image_id': '000000000885', 'image_path': '000000000885.jpg', 'generated_caption': 'A man in a white shirt and white shorts is playing tennis on a court. He is holding a tennis racket and appears to be in the middle of a swing. The man is wearing a hat and is focused on the game.', 'ground_truth_captions': ['a male tennis player in white shorts is playing tennis', 'This woman has just returned a volley in tennis', 'A man holding a tennis racket playing tennis.', 'The man balances on one leg after serving a tennis ball.', 'Someone playing in a tennis tournament with a crowd looking on.'], 'similarity_scores': [0.7916176319122314, 0.6029044389724731, 0.7826493382453918, 0.7831728458404541, 0.730663001537323], 'average_similarity': 0.7382014513015747, 'factual_correctness': 1, 'traditional_scores': {'Bleu_1': 0.34883720929421314, 'Bleu_2': 0.28819520884533556, 'Bleu_3': 0.21636477307789043, 'Bleu_4': 0.16601802039462785, 'ROUGE_L': np.float64(0.26852531181217903), 'CIDEr': np.float64(2.5083744440265165e-07)}}, {'image_id': '000000001000', 'image_path': '000000001000.jpg', 'generated_caption': 'A group of young tennis players posing for a photo on a tennis court.', 'ground_truth_captions': ['The people are posing for a group photo.', 'a large family poses for picture on tennis court', 'A group of young children standing next to each other.', 'A group of people that are standing near a tennis net.', 'A group of kids posing for a picture on a tennis court.'], 'similarity_scores': [0.8121464848518372, 0.8014275431632996, 0.9332407712936401, 0.9266008734703064, 0.96210777759552], 'average_similarity': 0.8871046900749207, 'factual_correctness': 1, 'traditional_scores': {'Bleu_1': 0.7857142856581634, 'Bleu_2': 0.6953534953135371, 'Bleu_3': 0.586228166010131, 'Bleu_4': 0.4374811430871823, 'ROUGE_L': np.float64(0.7800511508951408), 'CIDEr': np.float64(1.3886691844831387)}}, {'image_id': '000000001268', 'image_path': '000000001268.jpg', 'generated_caption': 'A man is sitting on a bench near a body of water, with a bird standing nearby. Another person is taking a picture of the scene.', 'ground_truth_captions': ['A beautiful woman taking a picture with her smart phone.', 'People underneath an arched bridge near the water.', 'A girl is taking a picture of people fishing.', 'The woman is taking a photo of the white goose next to the river.', 'A waterway under a bridge with people sitting down and a woman taking a photo.'], 'similarity_scores': [0.782329797744751, 0.8064131140708923, 0.9176195859909058, 0.9087253212928772, 0.792995035648346], 'average_similarity': 0.8416165709495544, 'factual_correctness': 1, 'traditional_scores': {'Bleu_1': 0.46153846152071015, 'Bleu_2': 0.3038218101131809, 'Bleu_3': 0.22596922817698423, 'Bleu_4': 0.17797644045043257, 'ROUGE_L': np.float64(0.375770020533881), 'CIDEr': np.float64(0.060854691988377924)}}, {'image_id': '000000001296', 'image_path': '000000001296.jpg', 'generated_caption': 'A woman is holding a Hello Kitty cell phone and looking at it.', 'ground_truth_captions': ['A woman holding a Hello Kitty phone on her hands.', 'A woman holds up her phone in front of her face.', 'A woman in white shirt holding up a cellphone.', 'A woman checking her cell phone with a hello kitty case.', 'The Asian girl is holding her Miss Kitty phone'], 'similarity_scores': [0.895054042339325, 0.963775098323822, 0.8877794146537781, 0.8548141717910767, 0.9150592684745789], 'average_similarity': 0.9032963991165162, 'factual_correctness': 1, 'traditional_scores': {'Bleu_1': 0.692307692254438, 'Bleu_2': 0.588348405367409, 'Bleu_3': 0.39777317387085076, 'Bleu_4': 0.2816609358577479, 'ROUGE_L': np.float64(0.6233576642335765), 'CIDEr': np.float64(1.1621915035268755)}}, {'image_id': '000000001353', 'image_path': '000000001353.jpg', 'generated_caption': 'A group of children are riding on a merry-go-round, enjoying the ride together.', 'ground_truth_captions': ['some children are riding on a mini orange train', 'Several children are riding on a toy train ride.', 'The children are riding on an indoor train. ', 'Several children on a small  indoor kiddie train.', 'A group of children ride on an indoor train.'], 'similarity_scores': [0.8839945793151855, 0.935627818107605, 0.9296435117721558, 0.8595176935195923, 0.9184918403625488], 'average_similarity': 0.9054550886154175, 'factual_correctness': 1, 'traditional_scores': {'Bleu_1': 0.692307692254438, 'Bleu_2': 0.6354889092513221, 'Bleu_3': 0.5683263035338306, 'Bleu_4': 0.4844273237538579, 'ROUGE_L': np.float64(0.4699537750385208), 'CIDEr': np.float64(1.8354976549464395)}}, {'image_id': '000000001425', 'image_path': '000000001425.jpg', 'generated_caption': 'A half-eaten pastry, possibly a doughnut, is sitting on a plate next to a bowl of sauce.', 'ground_truth_captions': ['A meal is lying on a plate on a table.', 'part of a sandwich sitting on a table', 'A plate with a burger that is halfway eaten. ', 'A half eaten meal sitting on a plate.', 'A sandwich with a bite taken on a plate.'], 'similarity_scores': [0.9454461932182312, 0.7800353765487671, 0.8442324995994568, 0.8539847731590271, 0.8317437171936035], 'average_similarity': 0.8510885119438172, 'factual_correctness': 1, 'traditional_scores': {'Bleu_1': 0.47058823526643606, 'Bleu_2': 0.29704426287498314, 'Bleu_3': 0.22743660193834345, 'Bleu_4': 3.02770291955685e-05, 'ROUGE_L': np.float64(0.4662420382165604), 'CIDEr': np.float64(0.19296587174744723)}}, {'image_id': '000000001490', 'image_path': '000000001490.jpg', 'generated_caption': 'A person is paddling on a surfboard in the ocean, surrounded by a calm sea.', 'ground_truth_captions': ['A man in a wet suit stands on a surfboard and rows with a paddle.', 'A paddle boarder on a large, still body of water.', 'A man is holding a long racquet on a surfboard in the middle of the sea.', 'Black and white of a person wearing a wetsuit standing on a surfboard and holding out a paddle, in a large body of water outside.', 'A man with a wet suit on standing on a surfboard in the water.'], 'similarity_scores': [0.8862621784210205, 0.8295203447341919, 0.9120904803276062, 0.8085383176803589, 0.8620437979698181], 'average_similarity': 0.8596910238265991, 'factual_correctness': 1, 'traditional_scores': {'Bleu_1': 0.6666666665777778, 'Bleu_2': 0.43643578041275427, 'Bleu_3': 0.35291723359715754, 'Bleu_4': 0.29256127303182505, 'ROUGE_L': np.float64(0.5131440588853837), 'CIDEr': np.float64(1.0646749758671115)}}, {'image_id': '000000001503', 'image_path': '000000001503.jpg', 'generated_caption': 'A white computer monitor is sitting on a desk next to a laptop.', 'ground_truth_captions': ['A computer on a desk next to a laptop.', 'A picture of an iMac desktop next to a Mac laptop on a desk. ', 'Two apple computers are on a white desk', 'A laptop and desktop computer on a white desk', 'A computer desk with several pieces of computer equipment.'], 'similarity_scores': [0.8663958311080933, 0.8651009798049927, 0.9453930258750916, 0.899527370929718, 0.8212477564811707], 'average_similarity': 0.8795329928398132, 'factual_correctness': 1, 'traditional_scores': {'Bleu_1': 0.7122777526922006, 'Bleu_2': 0.5742566830564967, 'Bleu_3': 0.5177586809240865, 'Bleu_4': 0.47616637362196346, 'ROUGE_L': np.float64(0.8459167950693374), 'CIDEr': np.float64(1.6487008208379907)}}, {'image_id': '000000001532', 'image_path': '000000001532.jpg', 'generated_caption': 'A busy highway with multiple cars and trucks driving under a freeway sign.', 'ground_truth_captions': ['A street scene with focus on the street signs on an overpass.', 'Many cars traveling on a busy road with exit signs overhead.', 'California traffic goes by road signs on an overpass indicating famous Hollywood streets.', 'Some cars on the freeway are exiting onto Sunset Blvd.', 'Cars and trucks driving under the underpass with street signs directing them where to go'], 'similarity_scores': [0.8697336912155151, 0.937811017036438, 0.8356293439865112, 0.7796680927276611, 0.908282458782196], 'average_similarity': 0.8662249207496643, 'factual_correctness': 1, 'traditional_scores': {'Bleu_1': 0.7692307691124263, 'Bleu_2': 0.43852900958464325, 'Bleu_3': 0.32699766805652825, 'Bleu_4': 0.24316915836394384, 'ROUGE_L': np.float64(0.2820809248554913), 'CIDEr': np.float64(0.5839971254318452)}}, {'image_id': '000000001584', 'image_path': '000000001584.jpg', 'generated_caption': 'A red double-decker bus is driving down a street, with a building in the background.', 'ground_truth_captions': ['The red, double decker bus is driving past other buses. ', 'A red double decker bus driving down a city street.', 'A red bus is driving on the road.', 'A double decker bus rolls along the streets.', 'a red double decker bus that is in the middle of the road'], 'similarity_scores': [0.8889199495315552, 0.843612015247345, 0.8969419002532959, 0.8537344336509705, 0.8123933672904968], 'average_similarity': 0.8591203331947327, 'factual_correctness': 1, 'traditional_scores': {'Bleu_1': 0.5999999999600001, 'Bleu_2': 0.5070925528020965, 'Bleu_3': 0.3407378427051567, 'Bleu_4': 4.261082723599193e-05, 'ROUGE_L': np.float64(0.5520361990950226), 'CIDEr': np.float64(0.8204604629896105)}}, {'image_id': '000000001675', 'image_path': '000000001675.jpg', 'generated_caption': 'A black and white cat is laying on a laptop computer.', 'ground_truth_captions': ['A cat resting on an open laptop computer.', 'A black fluffy cat sitting on top of a computer keyboard.', 'A black cat is sitting on a metal platform. ', 'The large cat is resting comfortably behind the laptop screen. ', 'A black and white cat relaxing inside a laptop.'], 'similarity_scores': [0.8737772703170776, 0.8860299587249756, 0.9559348225593567, 0.8950818777084351, 0.8904887437820435], 'average_similarity': 0.9002625346183777, 'factual_correctness': 1, 'traditional_scores': {'Bleu_1': 0.9090909089256201, 'Bleu_2': 0.797724035068799, 'Bleu_3': 0.5963868147931544, 'Bleu_4': 0.47987820657421176, 'ROUGE_L': np.float64(0.6110183639398998), 'CIDEr': np.float64(1.779448242063526)}}, {'image_id': '000000001761', 'image_path': '000000001761.jpg', 'generated_caption': \"A large airplane is flying over a bridge in the city, with the bridge's arches visible below. The airplane is positioned in the middle of the scene, and the bridge spans the entire width of the image.\", 'ground_truth_captions': ['Two planes flying in the sky over a bridge.', 'A sky photo to jumbo jet airplanes over a bridge.', 'Two planes fly over a bridge in Sydney, Australia, with the Sydney Opera House in the background.', 'two jets are flying over a bridge and some water', 'Two airplanes flying in the sky above a black bridge.'], 'similarity_scores': [0.7212255001068115, 0.7172260880470276, 0.8507752418518066, 0.7716518044471741, 0.7321873903274536], 'average_similarity': 0.7586132049560547, 'factual_correctness': 1, 'traditional_scores': {'Bleu_1': 0.2972972972892623, 'Bleu_2': 0.2225972810858974, 'Bleu_3': 0.16194379301356765, 'Bleu_4': 0.12572191856931514, 'ROUGE_L': np.float64(0.3251165889407063), 'CIDEr': np.float64(0.0007988694499899791)}}, {'image_id': '000000001818', 'image_path': '000000001818.jpg', 'generated_caption': 'A zebra is nuzzling its head under the belly of another zebra, possibly a mother and her baby.', 'ground_truth_captions': ['A zebra in the grass who is cleaning himself. ', \"A baby giraffe drinking milk from it's mother in a field.\", 'A baby zebra is suckling milk from its mother.', 'a baby zebra nursing from an adult zebra', 'Baby zebra sucking milk from its mothers teat. '], 'similarity_scores': [0.835252046585083, 0.7838693857192993, 0.9422412514686584, 0.8128725290298462, 0.8098879456520081], 'average_similarity': 0.836824631690979, 'factual_correctness': 1, 'traditional_scores': {'Bleu_1': 0.388888888867284, 'Bleu_2': 0.21389631596101674, 'Bleu_3': 1.4193697400876474e-06, 'Bleu_4': 3.7157701522892835e-09, 'ROUGE_L': np.float64(0.3152454780361757), 'CIDEr': np.float64(0.17030378048492478)}}, {'image_id': '000000001993', 'image_path': '000000001993.jpg', 'generated_caption': 'A bedroom with a bed, a chair, and a dining table. The bed has a colorful comforter on it.', 'ground_truth_captions': ['A bedroom with a bed and small table near by.', 'View of an apartment room with a bed an table and a view out the window.', 'A simple modern bedroom sheets on the bed', 'A bed room that has a table, chairs, and bed in it.', 'A room with purple walls, carpet and bed comforter.'], 'similarity_scores': [0.9260177612304688, 0.8000837564468384, 0.8219413757324219, 0.9223857522010803, 0.9159104824066162], 'average_similarity': 0.8772678256034852, 'factual_correctness': 1, 'traditional_scores': {'Bleu_1': 0.5263157894459835, 'Bleu_2': 0.38235955643025316, 'Bleu_3': 0.2581318877705712, 'Bleu_4': 0.18107197869842795, 'ROUGE_L': np.float64(0.3652694610778443), 'CIDEr': np.float64(0.2753806381637059)}}, {'image_id': '000000002006', 'image_path': '000000002006.jpg', 'generated_caption': \"A purple bus is driving down the street, with a man sitting in the driver's seat. The bus is heading towards the metro center, and there is a handicap sign on the front.\", 'ground_truth_captions': ['a big purple bus parked in a parking spot', \"A purple bus can't be missed on the city streets.\", 'a big purple public bus called south tyne', 'A city bus drives through a city area.', 'City bus driving through pedestrian saturated area near crosswalk.'], 'similarity_scores': [0.8375006914138794, 0.8596506714820862, 0.7881979942321777, 0.8768660426139832, 0.7189272046089172], 'average_similarity': 0.8162285208702087, 'factual_correctness': 1, 'traditional_scores': {'Bleu_1': 0.2727272727190084, 'Bleu_2': 0.1599005372617867, 'Bleu_3': 0.09378053745851062, 'Bleu_4': 1.2876689523960634e-05, 'ROUGE_L': np.float64(0.25738396624472576), 'CIDEr': np.float64(0.00017806372974739956)}}, {'image_id': '000000002149', 'image_path': '000000002149.jpg', 'generated_caption': 'A bowl filled with green apples, some of which are placed on top of each other.', 'ground_truth_captions': ['A large white bowl of many green apples. ', 'A white bowl of green granny smith apples.', 'A white bowl filled with green Granny Smith apples.', 'A bowl filled with many shiny  green apples.', 'A bowl full of fresh green apples are kept.'], 'similarity_scores': [0.9226332902908325, 0.8898783922195435, 0.9003108739852905, 0.9271273016929626, 0.8254778981208801], 'average_similarity': 0.8930855512619018, 'factual_correctness': 1, 'traditional_scores': {'Bleu_1': 0.4374999999726563, 'Bleu_2': 0.3415650255099273, 'Bleu_3': 0.2924017738017352, 'Bleu_4': 0.24903286386739962, 'ROUGE_L': np.float64(0.4212707182320442), 'CIDEr': np.float64(0.6850490856825)}}, {'image_id': '000000002153', 'image_path': '000000002153.jpg', 'generated_caption': 'A baseball player is holding a bat, ready to swing, while the catcher and umpire are positioned behind him.', 'ground_truth_captions': ['Batter preparing to swing at pitch during major game.', 'A baseball player swinging a bat over home plate.', 'A baseball player with a bat in his hand as the pitcher gets ready to throw the ball. ', 'A baseball game where the batter is waiting for the pitch.', 'there is a male tennis player that is at base'], 'similarity_scores': [0.5830568671226501, 0.8184176683425903, 0.7827561497688293, 0.7379368543624878, 0.7012471556663513], 'average_similarity': 0.7246829390525817, 'factual_correctness': 1, 'traditional_scores': {'Bleu_1': 0.4210526315567868, 'Bleu_2': 0.2649064713986791, 'Bleu_3': 0.1604151585007905, 'Bleu_4': 2.2537412721381717e-05, 'ROUGE_L': np.float64(0.40978886756238003), 'CIDEr': np.float64(0.31647973758328607)}}]\n"
     ]
    }
   ],
   "source": [
    "print(processed_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a0215957",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the cell with 'evaluate_standard_metrics'\n",
    "def evaluate_standard_metrics(references, candidates):\n",
    "    \"\"\"\n",
    "    Calculates standard captioning metrics (excluding CIDEr for batch processing).\n",
    "\n",
    "    Args:\n",
    "        references (dict): A dictionary mapping image IDs to lists of\n",
    "                           reference strings. e.g., {0: [\"ref1\", \"ref2\"], 1: [\"ref3\"]}\n",
    "        candidates (dict): A dictionary mapping image IDs to a list containing\n",
    "                           a single candidate string. e.g., {0: [\"cand1\"], 1: [\"cand2\"]}\n",
    "                           Note: The library expects a list of *one* candidate per image ID.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing scores for each metric (excluding CIDEr).\n",
    "    \"\"\"\n",
    "\n",
    "    scorers = [\n",
    "        (Bleu(4), [\"Bleu_1\", \"Bleu_2\", \"Bleu_3\", \"Bleu_4\"]), # Calculate BLEU-1 to BLEU-4\n",
    "        # (Meteor(),\"METEOR\"), # Requires JAVA Setup\n",
    "        (Rouge(), \"ROUGE_L\"),\n",
    "        # CIDEr removed - will be calculated in batch\n",
    "        # (Spice(), \"SPICE\") # Uncomment if SPICE/Java is set up\n",
    "    ]\n",
    "\n",
    "    all_scores = {}\n",
    "    for scorer, method in scorers:\n",
    "        # print(f'Computing {method} score...') # Optional: Modify print statement\n",
    "        try:\n",
    "            score, scores = scorer.compute_score(references, candidates)\n",
    "            if isinstance(method, list): # Handle BLEU returning multiple scores\n",
    "                for sc, m in zip(score, method): # Only need average scores here\n",
    "                    # print(f\"{m}: {sc:.4f}\")\n",
    "                    all_scores[m] = sc\n",
    "            else:\n",
    "                # print(f\"{method}: {score:.4f}\")\n",
    "                all_scores[method] = score\n",
    "        except Exception as e:\n",
    "            print(f\"Error computing {method}: {e}\")\n",
    "            if isinstance(method, list):\n",
    "                 for m in method: all_scores[m] = 0.0\n",
    "            else:\n",
    "                 all_scores[method] = 0.0\n",
    "\n",
    "\n",
    "    return all_scores\n",
    "\n",
    "# In the cell with 'add_traditional_scores'\n",
    "def add_traditional_scores(data):\n",
    "    \"\"\"\n",
    "    Adds traditional captioning scores to each item in the input data list.\n",
    "    Calculates CIDEr in batch for better accuracy.\n",
    "\n",
    "    Args:\n",
    "        data (list): A list of dictionaries, each containing image info,\n",
    "                     generated caption, and ground truth captions.\n",
    "\n",
    "    Returns:\n",
    "        list: The input list with an added 'traditional_scores' key\n",
    "              in each dictionary.\n",
    "    \"\"\"\n",
    "    processed_data = []\n",
    "    all_references = {}\n",
    "    all_candidates = {}\n",
    "\n",
    "    print(\"Calculating BLEU and ROUGE scores...\")\n",
    "    for i, item in enumerate(data):\n",
    "        image_id = item['image_id']\n",
    "        # Ensure image_id is suitable as a key (string or int, consistent)\n",
    "        # If image_id can be non-unique, use index 'i' or a unique identifier\n",
    "        key = image_id # Or use i if image_ids aren't unique/suitable\n",
    "\n",
    "        references_single = {key: item['ground_truth_captions']}\n",
    "        candidates_single = {key: [item['generated_caption']]}\n",
    "\n",
    "        # Calculate non-CIDEr scores for the current item\n",
    "        scores = evaluate_standard_metrics(references_single, candidates_single)\n",
    "        item['traditional_scores'] = scores # Initialize with BLEU/ROUGE\n",
    "\n",
    "        # Aggregate for batch CIDEr calculation\n",
    "        all_references[key] = item['ground_truth_captions']\n",
    "        all_candidates[key] = [item['generated_caption']]\n",
    "\n",
    "        processed_data.append(item) # Add item early\n",
    "\n",
    "    # Calculate CIDEr scores in batch\n",
    "    print(\"\\nCalculating CIDEr score...\")\n",
    "    cider_scorer = Cider()\n",
    "    try:\n",
    "        cider_avg_score, cider_scores_list = cider_scorer.compute_score(all_references, all_candidates)\n",
    "        print(f\"CIDEr (Avg): {cider_avg_score:.4f}\")\n",
    "\n",
    "        # Add individual CIDEr scores back to the items\n",
    "        # Ensure the order of cider_scores_list matches the order of items\n",
    "        # This assumes compute_score preserves the order based on the keys passed\n",
    "        # It's safer to map scores back using the keys if order isn't guaranteed\n",
    "        keys_order = list(all_references.keys()) # Get the order in which keys were processed\n",
    "        scores_dict = dict(zip(keys_order, cider_scores_list))\n",
    "\n",
    "        for item in processed_data:\n",
    "             key = item['image_id'] # Or use the same key logic as above\n",
    "             item['traditional_scores']['CIDEr'] = scores_dict.get(key, 0.0) # Add CIDEr score\n",
    "\n",
    "    except Exception as e:\n",
    "         print(f\"Error computing CIDEr: {e}\")\n",
    "         # Assign 0.0 if CIDEr fails\n",
    "         for item in processed_data:\n",
    "             item['traditional_scores']['CIDEr'] = 0.0\n",
    "\n",
    "\n",
    "    # --- Optional: Calculate SPICE similarly in batch if needed ---\n",
    "    # print(\"\\nCalculating SPICE score...\")\n",
    "    # spice_scorer = Spice()\n",
    "    # try:\n",
    "    #     spice_avg_score, spice_scores_list = spice_scorer.compute_score(all_references, all_candidates)\n",
    "    #     print(f\"SPICE (Avg): {spice_avg_score:.4f}\")\n",
    "    #     spice_scores_dict = {item['image_id']: score for item, score in zip(data, spice_scores_list)} # Assuming order preservation\n",
    "    #     for item in processed_data:\n",
    "    #          item['traditional_scores']['SPICE'] = spice_scores_dict.get(item['image_id'], 0.0)\n",
    "    # except Exception as e:\n",
    "    #      print(f\"Error computing SPICE: {e}. Ensure Java and Stanford CoreNLP are set up.\")\n",
    "    #      for item in processed_data:\n",
    "    #          item['traditional_scores']['SPICE'] = 0.0\n",
    "    # --- End Optional SPICE ---\n",
    "\n",
    "\n",
    "    return processed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9752a36",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
